---
description: "Performance optimization using Benchmarker and Simulator neurons"
---

**PERFORMANCE OPTIMIZATION MODE** ⚡

Optimize code performance using quantum-enhanced analysis:

## Phase 1: Benchmark & Profile

Activate **BenchmarkerNeuron** to measure current performance:

### Metrics to Collect
- Execution time (average, p50, p95, p99)
- Memory usage (heap, stack, allocations)
- CPU utilization
- I/O operations
- Network latency
- Database query performance
- Cache hit rates
- Garbage collection pauses

### Profiling Techniques
- Time-based profiling
- Memory profiling
- Allocation tracking
- Flame graphs
- Call tree analysis

## Phase 2: Simulate & Analyze

Activate **SimulatorNeuron** to model optimizations:

### What-If Scenarios
- Algorithm complexity changes (O(n²) → O(n log n))
- Caching strategies (LRU, LFU, TTL)
- Parallelization opportunities
- Database index optimization
- Query optimization
- Memory pooling
- Lazy loading vs. eager loading
- Batch processing

### Simulation Outputs
- Projected performance gains
- Resource trade-offs
- Scalability impacts
- Cost implications

## Phase 3: Optimize

Apply optimizations with **highest ROI**:

### Optimization Categories

**Algorithmic**:
- Better algorithms and data structures
- Reduce complexity
- Early termination
- Memoization

**I/O**:
- Batch operations
- Async/await patterns
- Connection pooling
- Streaming

**Memory**:
- Object pooling
- Reduce allocations
- Efficient data structures
- Memory-mapped files

**Caching**:
- Multi-level caching
- Cache warming
- Invalidation strategies

**Database**:
- Query optimization
- Index tuning
- N+1 query elimination
- Denormalization where appropriate

## Quantum Enhancement

- **Wormhole Navigation**: Find similar optimization patterns in memory
- **COPL Learning**: Apply successful optimization strategies
- **Momentum Recursion**: Iteratively improve until performance targets met
- **PPQ Introspection**: Validate performance claims with benchmarks

## Output Format

1. **Current Performance Baseline**
   - Key metrics before optimization

2. **Bottleneck Analysis**
   - Top performance issues ranked by impact

3. **Optimization Plan**
   - Recommended changes prioritized by ROI
   - Expected performance improvements
   - Implementation complexity

4. **Simulated Results**
   - Projected metrics after optimizations
   - Scalability predictions

5. **Implementation Steps**
   - Detailed code changes
   - Testing strategy
   - Rollback plan

Measure twice, optimize once. Every recommendation should be data-driven.
